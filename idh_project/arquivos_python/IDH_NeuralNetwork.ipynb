{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PAÍS</th>\n",
       "      <th>PIB</th>\n",
       "      <th>ILE</th>\n",
       "      <th>IPC</th>\n",
       "      <th>ClassIDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>Emirados Árabes Unidos</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>7.28</td>\n",
       "      <td>71</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>Polônia</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>7.20</td>\n",
       "      <td>58</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>7.79</td>\n",
       "      <td>62</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>França</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>7.55</td>\n",
       "      <td>69</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Finlândia</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>7.92</td>\n",
       "      <td>86</td>\n",
       "      <td>Alto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                    PAÍS       PIB   ILE  IPC ClassIDH\n",
       "0          47  Emirados Árabes Unidos  0.005014  7.28   71     Alto\n",
       "1         121                 Polônia  0.007092  7.20   58     Alto\n",
       "2         122                Portugal  0.002916  7.79   62     Alto\n",
       "3          57                  França  0.030892  7.55   69     Alto\n",
       "4          56               Finlândia  0.000332  7.92   86     Alto"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Carregamento da base de dados\n",
    "base = pd.read_csv('idh_classificado.csv')\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analisando o formato\n",
    "base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropando a coluna Unnamed\n",
    "base.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto',\n",
       "       'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto',\n",
       "       'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto',\n",
       "       'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto',\n",
       "       'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto',\n",
       "       'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto',\n",
       "       'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto',\n",
       "       'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Alto', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio', 'Médio',\n",
       "       'Médio', 'Médio', 'Médio', 'Médio', 'Baixo', 'Baixo', 'Baixo',\n",
       "       'Baixo', 'Baixo', 'Baixo', 'Baixo', 'Baixo', 'Baixo', 'Baixo',\n",
       "       'Baixo', 'Baixo', 'Baixo', 'Baixo', 'Baixo', 'Baixo', 'Baixo'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definindo variáveis independentes e variáveis dependentes\n",
    "previsores = base.iloc[:,2:4].values\n",
    "classe = base.iloc[:,4].values\n",
    "classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codificando a coluna categórica (classe)\n",
    "labelencoding = LabelEncoder()\n",
    "base[\"ClassIDH\"] = labelencoding.fit_transform(base[\"ClassIDH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criação da classe dummy\n",
    "classe_dummy = np_utils.to_categorical(base[\"ClassIDH\"])\n",
    "classe_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizando os dado na lista previsores\n",
    "normalizar = MinMaxScaler(feature_range = (0,1))\n",
    "normalizados = normalizar.fit_transform(previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.28, 71.  ],\n",
       "       [ 7.2 , 58.  ],\n",
       "       [ 7.79, 62.  ],\n",
       "       [ 7.55, 69.  ],\n",
       "       [ 7.92, 86.  ],\n",
       "       [ 8.11, 74.  ],\n",
       "       [ 8.24, 69.  ],\n",
       "       [ 7.89, 62.  ],\n",
       "       [ 7.43, 60.  ],\n",
       "       [ 7.61, 50.  ],\n",
       "       [ 8.15, 77.  ],\n",
       "       [ 8.03, 54.  ],\n",
       "       [ 7.87, 56.  ],\n",
       "       [ 7.88, 44.  ],\n",
       "       [ 8.17, 87.  ],\n",
       "       [ 7.36, 47.  ],\n",
       "       [ 8.26, 56.  ],\n",
       "       [ 7.15, 48.  ],\n",
       "       [ 7.79, 36.  ],\n",
       "       [ 6.69, 52.  ],\n",
       "       [ 7.84, 80.  ],\n",
       "       [ 8.21, 60.  ],\n",
       "       [ 7.94, 56.  ],\n",
       "       [ 6.72, 40.  ],\n",
       "       [ 7.64, 45.  ],\n",
       "       [ 7.98, 73.  ],\n",
       "       [ 7.61, 53.  ],\n",
       "       [ 7.68, 56.  ],\n",
       "       [ 7.63, 60.  ],\n",
       "       [ 8.21, 74.  ],\n",
       "       [ 8.16, 52.  ],\n",
       "       [ 7.72, 84.  ],\n",
       "       [ 7.53, 44.  ],\n",
       "       [ 8.91, 76.  ],\n",
       "       [ 7.96, 82.  ],\n",
       "       [ 8.56, 87.  ],\n",
       "       [ 7.9 , 78.  ],\n",
       "       [ 7.61, 59.  ],\n",
       "       [ 7.52, 53.  ],\n",
       "       [ 8.2 , 77.  ],\n",
       "       [ 6.85, 53.  ],\n",
       "       [ 7.3 , 60.  ],\n",
       "       [ 7.76, 43.  ],\n",
       "       [ 7.56, 64.  ],\n",
       "       [ 6.7 , 28.  ],\n",
       "       [ 7.62, 75.  ],\n",
       "       [ 8.48, 85.  ],\n",
       "       [ 7.72, 85.  ],\n",
       "       [ 7.86, 77.  ],\n",
       "       [ 7.36, 71.  ],\n",
       "       [ 6.91, 62.  ],\n",
       "       [ 8.06, 77.  ],\n",
       "       [ 7.09, 62.  ],\n",
       "       [ 7.91, 80.  ],\n",
       "       [ 7.52, 34.  ],\n",
       "       [ 8.81, 85.  ],\n",
       "       [ 7.85, 67.  ],\n",
       "       [ 7.22, 39.  ],\n",
       "       [ 7.89, 58.  ],\n",
       "       [ 7.33, 42.  ],\n",
       "       [ 6.88, 45.  ],\n",
       "       [ 5.5 , 45.  ],\n",
       "       [ 7.35, 53.  ],\n",
       "       [ 6.76, 52.  ],\n",
       "       [ 6.2 , 30.  ],\n",
       "       [ 7.38, 35.  ],\n",
       "       [ 5.94, 29.  ],\n",
       "       [ 7.3 , 32.  ],\n",
       "       [ 7.2 , 29.  ],\n",
       "       [ 6.49, 28.  ],\n",
       "       [ 6.69, 41.  ],\n",
       "       [ 6.26, 37.  ],\n",
       "       [ 7.42, 28.  ],\n",
       "       [ 6.71, 34.  ],\n",
       "       [ 7.27, 40.  ],\n",
       "       [ 6.97, 26.  ],\n",
       "       [ 6.25, 45.  ],\n",
       "       [ 7.58, 28.  ],\n",
       "       [ 5.19, 13.  ],\n",
       "       [ 6.78, 38.  ],\n",
       "       [ 4.19, 16.  ],\n",
       "       [ 7.17, 30.  ],\n",
       "       [ 6.94, 28.  ],\n",
       "       [ 6.14, 44.  ],\n",
       "       [ 6.87, 36.  ],\n",
       "       [ 7.78, 36.  ],\n",
       "       [ 6.5 , 25.  ],\n",
       "       [ 6.75, 37.  ],\n",
       "       [ 7.22, 28.  ],\n",
       "       [ 5.95, 32.  ],\n",
       "       [ 6.19, 38.  ],\n",
       "       [ 6.23, 28.  ],\n",
       "       [ 5.97, 43.  ],\n",
       "       [ 7.04, 22.  ],\n",
       "       [ 6.97, 44.  ],\n",
       "       [ 5.74, 20.  ],\n",
       "       [ 4.94, 24.  ],\n",
       "       [ 6.69, 41.  ],\n",
       "       [ 6.28, 31.  ],\n",
       "       [ 5.8 , 31.  ],\n",
       "       [ 7.42, 34.  ],\n",
       "       [ 6.86, 36.  ],\n",
       "       [ 6.68, 38.  ],\n",
       "       [ 6.33, 24.  ],\n",
       "       [ 7.62, 61.  ],\n",
       "       [ 7.39, 34.  ],\n",
       "       [ 5.68, 35.  ],\n",
       "       [ 6.68, 30.  ],\n",
       "       [ 6.63, 35.  ],\n",
       "       [ 6.55, 25.  ],\n",
       "       [ 6.82, 37.  ],\n",
       "       [ 6.53, 41.  ],\n",
       "       [ 7.22, 20.  ],\n",
       "       [ 5.86, 25.  ],\n",
       "       [ 7.8 , 26.  ],\n",
       "       [ 7.65, 58.  ],\n",
       "       [ 6.52, 40.  ],\n",
       "       [ 6.05, 26.  ],\n",
       "       [ 7.81, 35.  ],\n",
       "       [ 7.13, 35.  ],\n",
       "       [ 4.79, 18.  ],\n",
       "       [ 5.5 , 26.  ],\n",
       "       [ 6.76, 28.  ],\n",
       "       [ 4.9 , 35.  ],\n",
       "       [ 6.57, 40.  ],\n",
       "       [ 6.62, 41.  ],\n",
       "       [ 7.59, 48.  ],\n",
       "       [ 6.6 , 29.  ],\n",
       "       [ 7.09, 34.  ],\n",
       "       [ 5.06, 26.  ],\n",
       "       [ 7.26, 40.  ],\n",
       "       [ 8.03, 42.  ],\n",
       "       [ 6.66, 41.  ],\n",
       "       [ 6.44, 30.  ],\n",
       "       [ 7.26, 26.  ],\n",
       "       [ 6.51, 18.  ],\n",
       "       [ 7.71, 43.  ],\n",
       "       [ 6.82, 68.  ],\n",
       "       [ 6.04, 40.  ],\n",
       "       [ 5.65, 19.  ],\n",
       "       [ 5.96, 31.  ],\n",
       "       [ 6.15, 33.  ],\n",
       "       [ 5.08, 19.  ],\n",
       "       [ 5.36, 18.  ],\n",
       "       [ 5.87, 37.  ],\n",
       "       [ 7.04, 37.  ],\n",
       "       [ 5.62, 29.  ],\n",
       "       [ 6.06, 18.  ],\n",
       "       [ 5.45, 15.  ],\n",
       "       [ 5.97, 32.  ],\n",
       "       [ 6.15, 26.  ],\n",
       "       [ 6.35, 28.  ],\n",
       "       [ 5.83, 29.  ],\n",
       "       [ 5.6 , 20.  ],\n",
       "       [ 5.36, 25.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previsores originais\n",
    "previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('previsores.npy', previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65466102, 0.78378378],\n",
       "       [0.63771186, 0.60810811],\n",
       "       [0.76271186, 0.66216216],\n",
       "       [0.71186441, 0.75675676],\n",
       "       [0.79025424, 0.98648649],\n",
       "       [0.83050847, 0.82432432],\n",
       "       [0.85805085, 0.75675676],\n",
       "       [0.78389831, 0.66216216],\n",
       "       [0.68644068, 0.63513514],\n",
       "       [0.72457627, 0.5       ],\n",
       "       [0.83898305, 0.86486486],\n",
       "       [0.81355932, 0.55405405],\n",
       "       [0.77966102, 0.58108108],\n",
       "       [0.78177966, 0.41891892],\n",
       "       [0.84322034, 1.        ],\n",
       "       [0.67161017, 0.45945946],\n",
       "       [0.86228814, 0.58108108],\n",
       "       [0.62711864, 0.47297297],\n",
       "       [0.76271186, 0.31081081],\n",
       "       [0.52966102, 0.52702703],\n",
       "       [0.77330508, 0.90540541],\n",
       "       [0.85169492, 0.63513514],\n",
       "       [0.79449153, 0.58108108],\n",
       "       [0.53601695, 0.36486486],\n",
       "       [0.7309322 , 0.43243243],\n",
       "       [0.8029661 , 0.81081081],\n",
       "       [0.72457627, 0.54054054],\n",
       "       [0.73940678, 0.58108108],\n",
       "       [0.72881356, 0.63513514],\n",
       "       [0.85169492, 0.82432432],\n",
       "       [0.84110169, 0.52702703],\n",
       "       [0.74788136, 0.95945946],\n",
       "       [0.70762712, 0.41891892],\n",
       "       [1.        , 0.85135135],\n",
       "       [0.79872881, 0.93243243],\n",
       "       [0.92584746, 1.        ],\n",
       "       [0.78601695, 0.87837838],\n",
       "       [0.72457627, 0.62162162],\n",
       "       [0.70550847, 0.54054054],\n",
       "       [0.84957627, 0.86486486],\n",
       "       [0.56355932, 0.54054054],\n",
       "       [0.65889831, 0.63513514],\n",
       "       [0.75635593, 0.40540541],\n",
       "       [0.71398305, 0.68918919],\n",
       "       [0.53177966, 0.2027027 ],\n",
       "       [0.72669492, 0.83783784],\n",
       "       [0.90889831, 0.97297297],\n",
       "       [0.74788136, 0.97297297],\n",
       "       [0.77754237, 0.86486486],\n",
       "       [0.67161017, 0.78378378],\n",
       "       [0.57627119, 0.66216216],\n",
       "       [0.81991525, 0.86486486],\n",
       "       [0.61440678, 0.66216216],\n",
       "       [0.78813559, 0.90540541],\n",
       "       [0.70550847, 0.28378378],\n",
       "       [0.97881356, 0.97297297],\n",
       "       [0.77542373, 0.72972973],\n",
       "       [0.64194915, 0.35135135],\n",
       "       [0.78389831, 0.60810811],\n",
       "       [0.66525424, 0.39189189],\n",
       "       [0.56991525, 0.43243243],\n",
       "       [0.27754237, 0.43243243],\n",
       "       [0.66949153, 0.54054054],\n",
       "       [0.54449153, 0.52702703],\n",
       "       [0.42584746, 0.22972973],\n",
       "       [0.67584746, 0.2972973 ],\n",
       "       [0.37076271, 0.21621622],\n",
       "       [0.65889831, 0.25675676],\n",
       "       [0.63771186, 0.21621622],\n",
       "       [0.48728814, 0.2027027 ],\n",
       "       [0.52966102, 0.37837838],\n",
       "       [0.43855932, 0.32432432],\n",
       "       [0.68432203, 0.2027027 ],\n",
       "       [0.53389831, 0.28378378],\n",
       "       [0.65254237, 0.36486486],\n",
       "       [0.58898305, 0.17567568],\n",
       "       [0.43644068, 0.43243243],\n",
       "       [0.71822034, 0.2027027 ],\n",
       "       [0.21186441, 0.        ],\n",
       "       [0.54872881, 0.33783784],\n",
       "       [0.        , 0.04054054],\n",
       "       [0.63135593, 0.22972973],\n",
       "       [0.58262712, 0.2027027 ],\n",
       "       [0.41313559, 0.41891892],\n",
       "       [0.56779661, 0.31081081],\n",
       "       [0.76059322, 0.31081081],\n",
       "       [0.48940678, 0.16216216],\n",
       "       [0.54237288, 0.32432432],\n",
       "       [0.64194915, 0.2027027 ],\n",
       "       [0.37288136, 0.25675676],\n",
       "       [0.42372881, 0.33783784],\n",
       "       [0.43220339, 0.2027027 ],\n",
       "       [0.37711864, 0.40540541],\n",
       "       [0.60381356, 0.12162162],\n",
       "       [0.58898305, 0.41891892],\n",
       "       [0.32838983, 0.09459459],\n",
       "       [0.15889831, 0.14864865],\n",
       "       [0.52966102, 0.37837838],\n",
       "       [0.44279661, 0.24324324],\n",
       "       [0.34110169, 0.24324324],\n",
       "       [0.68432203, 0.28378378],\n",
       "       [0.56567797, 0.31081081],\n",
       "       [0.52754237, 0.33783784],\n",
       "       [0.45338983, 0.14864865],\n",
       "       [0.72669492, 0.64864865],\n",
       "       [0.6779661 , 0.28378378],\n",
       "       [0.31567797, 0.2972973 ],\n",
       "       [0.52754237, 0.22972973],\n",
       "       [0.51694915, 0.2972973 ],\n",
       "       [0.5       , 0.16216216],\n",
       "       [0.55720339, 0.32432432],\n",
       "       [0.49576271, 0.37837838],\n",
       "       [0.64194915, 0.09459459],\n",
       "       [0.35381356, 0.16216216],\n",
       "       [0.76483051, 0.17567568],\n",
       "       [0.73305085, 0.60810811],\n",
       "       [0.49364407, 0.36486486],\n",
       "       [0.3940678 , 0.17567568],\n",
       "       [0.76694915, 0.2972973 ],\n",
       "       [0.62288136, 0.2972973 ],\n",
       "       [0.12711864, 0.06756757],\n",
       "       [0.27754237, 0.17567568],\n",
       "       [0.54449153, 0.2027027 ],\n",
       "       [0.15042373, 0.2972973 ],\n",
       "       [0.50423729, 0.36486486],\n",
       "       [0.51483051, 0.37837838],\n",
       "       [0.72033898, 0.47297297],\n",
       "       [0.51059322, 0.21621622],\n",
       "       [0.61440678, 0.28378378],\n",
       "       [0.18432203, 0.17567568],\n",
       "       [0.65042373, 0.36486486],\n",
       "       [0.81355932, 0.39189189],\n",
       "       [0.52330508, 0.37837838],\n",
       "       [0.47669492, 0.22972973],\n",
       "       [0.65042373, 0.17567568],\n",
       "       [0.49152542, 0.06756757],\n",
       "       [0.74576271, 0.40540541],\n",
       "       [0.55720339, 0.74324324],\n",
       "       [0.39194915, 0.36486486],\n",
       "       [0.30932203, 0.08108108],\n",
       "       [0.375     , 0.24324324],\n",
       "       [0.41525424, 0.27027027],\n",
       "       [0.18855932, 0.08108108],\n",
       "       [0.24788136, 0.06756757],\n",
       "       [0.3559322 , 0.32432432],\n",
       "       [0.60381356, 0.32432432],\n",
       "       [0.3029661 , 0.21621622],\n",
       "       [0.39618644, 0.06756757],\n",
       "       [0.26694915, 0.02702703],\n",
       "       [0.37711864, 0.25675676],\n",
       "       [0.41525424, 0.17567568],\n",
       "       [0.45762712, 0.2027027 ],\n",
       "       [0.34745763, 0.21621622],\n",
       "       [0.29872881, 0.09459459],\n",
       "       [0.24788136, 0.16216216]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previsores normalizados\n",
    "normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('normalizados.npy', normalizados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo dados entre treino e teste definindo 30% para teste\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(normalizados,\n",
    "                                                       classe_dummy,\n",
    "                                                       test_size = 0.2,\n",
    "                                                       random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação da estrutura da rede neural com a classe Sequential (sequência de camadas)\n",
    "modelo = Sequential()\n",
    "#Primeira camada oculta e camada de entrada\n",
    "modelo.add(Dense(units = 3, input_dim = 2))\n",
    "#Segunda camada oculta\n",
    "modelo.add(Dense(units = 3))\n",
    "#Função de ativação Softmax para classificação de mais de duas classes (é gerada uma probablidade em cada neurônio)\n",
    "modelo.add(Dense(units = 3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 3)                 9         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 12        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sumário da estrutura\n",
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.5820 - accuracy: 0.5000 - val_loss: 1.7213 - val_accuracy: 0.4516\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.5545 - accuracy: 0.5000 - val_loss: 1.6927 - val_accuracy: 0.4516\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.5306 - accuracy: 0.5000 - val_loss: 1.6651 - val_accuracy: 0.4516\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.5085 - accuracy: 0.4919 - val_loss: 1.6376 - val_accuracy: 0.4516\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4848 - accuracy: 0.4919 - val_loss: 1.6114 - val_accuracy: 0.4516\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.4626 - accuracy: 0.4919 - val_loss: 1.5863 - val_accuracy: 0.4516\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4423 - accuracy: 0.4919 - val_loss: 1.5620 - val_accuracy: 0.4516\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4204 - accuracy: 0.4919 - val_loss: 1.5395 - val_accuracy: 0.4516\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4028 - accuracy: 0.4919 - val_loss: 1.5173 - val_accuracy: 0.4194\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.3832 - accuracy: 0.4919 - val_loss: 1.4965 - val_accuracy: 0.4194\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3662 - accuracy: 0.4839 - val_loss: 1.4763 - val_accuracy: 0.4194\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3504 - accuracy: 0.4839 - val_loss: 1.4568 - val_accuracy: 0.4194\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3345 - accuracy: 0.4839 - val_loss: 1.4383 - val_accuracy: 0.4194\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3191 - accuracy: 0.4839 - val_loss: 1.4210 - val_accuracy: 0.4194\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.3060 - accuracy: 0.4839 - val_loss: 1.4042 - val_accuracy: 0.4194\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2915 - accuracy: 0.4839 - val_loss: 1.3888 - val_accuracy: 0.4194\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2800 - accuracy: 0.4839 - val_loss: 1.3736 - val_accuracy: 0.4194\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2678 - accuracy: 0.4839 - val_loss: 1.3591 - val_accuracy: 0.4194\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2563 - accuracy: 0.4758 - val_loss: 1.3455 - val_accuracy: 0.4194\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2444 - accuracy: 0.4677 - val_loss: 1.3330 - val_accuracy: 0.4194\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2341 - accuracy: 0.4597 - val_loss: 1.3209 - val_accuracy: 0.4194\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2255 - accuracy: 0.4597 - val_loss: 1.3088 - val_accuracy: 0.4194\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2165 - accuracy: 0.4516 - val_loss: 1.2972 - val_accuracy: 0.4194\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2059 - accuracy: 0.4516 - val_loss: 1.2868 - val_accuracy: 0.4194\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1975 - accuracy: 0.4435 - val_loss: 1.2767 - val_accuracy: 0.4194\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.1895 - accuracy: 0.4355 - val_loss: 1.2670 - val_accuracy: 0.4194\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1819 - accuracy: 0.4355 - val_loss: 1.2574 - val_accuracy: 0.4194\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1743 - accuracy: 0.4274 - val_loss: 1.2482 - val_accuracy: 0.3871\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1674 - accuracy: 0.4274 - val_loss: 1.2392 - val_accuracy: 0.3871\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1593 - accuracy: 0.4194 - val_loss: 1.2312 - val_accuracy: 0.3871\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1537 - accuracy: 0.4113 - val_loss: 1.2228 - val_accuracy: 0.2903\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1464 - accuracy: 0.4032 - val_loss: 1.2152 - val_accuracy: 0.2903\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1405 - accuracy: 0.3952 - val_loss: 1.2076 - val_accuracy: 0.2581\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1341 - accuracy: 0.3952 - val_loss: 1.2004 - val_accuracy: 0.2258\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1286 - accuracy: 0.3871 - val_loss: 1.1932 - val_accuracy: 0.1935\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1227 - accuracy: 0.3871 - val_loss: 1.1864 - val_accuracy: 0.1613\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1171 - accuracy: 0.3629 - val_loss: 1.1798 - val_accuracy: 0.1613\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1120 - accuracy: 0.3387 - val_loss: 1.1733 - val_accuracy: 0.1613\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.1066 - accuracy: 0.3306 - val_loss: 1.1671 - val_accuracy: 0.1613\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.1015 - accuracy: 0.3226 - val_loss: 1.1612 - val_accuracy: 0.1613\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0967 - accuracy: 0.3065 - val_loss: 1.1554 - val_accuracy: 0.1613\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0917 - accuracy: 0.2903 - val_loss: 1.1498 - val_accuracy: 0.1613\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0869 - accuracy: 0.2823 - val_loss: 1.1444 - val_accuracy: 0.1613\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0826 - accuracy: 0.2823 - val_loss: 1.1391 - val_accuracy: 0.1613\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0782 - accuracy: 0.2742 - val_loss: 1.1339 - val_accuracy: 0.1613\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0736 - accuracy: 0.2742 - val_loss: 1.1291 - val_accuracy: 0.1613\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0692 - accuracy: 0.2581 - val_loss: 1.1245 - val_accuracy: 0.1613\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0657 - accuracy: 0.2500 - val_loss: 1.1197 - val_accuracy: 0.1613\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0614 - accuracy: 0.2419 - val_loss: 1.1150 - val_accuracy: 0.1290\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0575 - accuracy: 0.2419 - val_loss: 1.1106 - val_accuracy: 0.1290\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.0533 - accuracy: 0.2339 - val_loss: 1.1064 - val_accuracy: 0.0968\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0501 - accuracy: 0.2016 - val_loss: 1.1020 - val_accuracy: 0.0968\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0465 - accuracy: 0.1855 - val_loss: 1.0978 - val_accuracy: 0.0968\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0425 - accuracy: 0.1855 - val_loss: 1.0941 - val_accuracy: 0.0968\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0393 - accuracy: 0.1855 - val_loss: 1.0902 - val_accuracy: 0.0968\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0359 - accuracy: 0.1774 - val_loss: 1.0865 - val_accuracy: 0.0968\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0325 - accuracy: 0.1774 - val_loss: 1.0829 - val_accuracy: 0.0968\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0292 - accuracy: 0.1694 - val_loss: 1.0795 - val_accuracy: 0.0968\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0261 - accuracy: 0.1694 - val_loss: 1.0763 - val_accuracy: 0.0968\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0229 - accuracy: 0.1694 - val_loss: 1.0730 - val_accuracy: 0.0968\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0199 - accuracy: 0.1694 - val_loss: 1.0700 - val_accuracy: 0.0968\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0169 - accuracy: 0.1694 - val_loss: 1.0668 - val_accuracy: 0.0968\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0142 - accuracy: 0.1613 - val_loss: 1.0638 - val_accuracy: 0.0968\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0113 - accuracy: 0.1613 - val_loss: 1.0610 - val_accuracy: 0.0968\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0086 - accuracy: 0.1694 - val_loss: 1.0582 - val_accuracy: 0.0968\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0057 - accuracy: 0.1694 - val_loss: 1.0552 - val_accuracy: 0.0968\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0034 - accuracy: 0.1532 - val_loss: 1.0523 - val_accuracy: 0.0968\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0009 - accuracy: 0.1532 - val_loss: 1.0500 - val_accuracy: 0.0968\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9979 - accuracy: 0.1694 - val_loss: 1.0474 - val_accuracy: 0.0968\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9956 - accuracy: 0.1694 - val_loss: 1.0450 - val_accuracy: 0.0968\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9935 - accuracy: 0.1694 - val_loss: 1.0423 - val_accuracy: 0.0968\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9910 - accuracy: 0.1694 - val_loss: 1.0398 - val_accuracy: 0.0968\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9888 - accuracy: 0.1694 - val_loss: 1.0373 - val_accuracy: 0.0968\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9866 - accuracy: 0.1532 - val_loss: 1.0349 - val_accuracy: 0.0968\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9843 - accuracy: 0.1532 - val_loss: 1.0328 - val_accuracy: 0.0968\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9821 - accuracy: 0.1613 - val_loss: 1.0305 - val_accuracy: 0.0968\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9802 - accuracy: 0.1532 - val_loss: 1.0282 - val_accuracy: 0.0968\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9783 - accuracy: 0.1613 - val_loss: 1.0260 - val_accuracy: 0.0968\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9762 - accuracy: 0.1694 - val_loss: 1.0239 - val_accuracy: 0.0968\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9744 - accuracy: 0.1694 - val_loss: 1.0223 - val_accuracy: 0.0968\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9723 - accuracy: 0.1694 - val_loss: 1.0202 - val_accuracy: 0.0968\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9704 - accuracy: 0.1694 - val_loss: 1.0183 - val_accuracy: 0.0968\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9686 - accuracy: 0.1694 - val_loss: 1.0164 - val_accuracy: 0.0968\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9670 - accuracy: 0.1694 - val_loss: 1.0144 - val_accuracy: 0.0968\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9651 - accuracy: 0.1694 - val_loss: 1.0125 - val_accuracy: 0.0968\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9635 - accuracy: 0.1694 - val_loss: 1.0105 - val_accuracy: 0.0968\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9617 - accuracy: 0.1774 - val_loss: 1.0088 - val_accuracy: 0.1290\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9600 - accuracy: 0.1855 - val_loss: 1.0071 - val_accuracy: 0.1290\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9584 - accuracy: 0.1855 - val_loss: 1.0051 - val_accuracy: 0.1290\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9569 - accuracy: 0.1935 - val_loss: 1.0034 - val_accuracy: 0.1613\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9552 - accuracy: 0.1935 - val_loss: 1.0017 - val_accuracy: 0.1613\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9537 - accuracy: 0.2097 - val_loss: 1.0001 - val_accuracy: 0.1613\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9521 - accuracy: 0.2177 - val_loss: 0.9984 - val_accuracy: 0.1613\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9507 - accuracy: 0.2177 - val_loss: 0.9967 - val_accuracy: 0.1613\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9490 - accuracy: 0.2419 - val_loss: 0.9950 - val_accuracy: 0.1613\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9476 - accuracy: 0.2419 - val_loss: 0.9932 - val_accuracy: 0.1613\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9461 - accuracy: 0.2339 - val_loss: 0.9915 - val_accuracy: 0.1935\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9446 - accuracy: 0.2419 - val_loss: 0.9898 - val_accuracy: 0.2258\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9433 - accuracy: 0.2500 - val_loss: 0.9882 - val_accuracy: 0.2258\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9417 - accuracy: 0.2661 - val_loss: 0.9864 - val_accuracy: 0.2258\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9404 - accuracy: 0.2581 - val_loss: 0.9847 - val_accuracy: 0.2258\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9389 - accuracy: 0.2903 - val_loss: 0.9832 - val_accuracy: 0.2258\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9376 - accuracy: 0.3145 - val_loss: 0.9817 - val_accuracy: 0.2581\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9361 - accuracy: 0.3306 - val_loss: 0.9800 - val_accuracy: 0.2581\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9348 - accuracy: 0.3306 - val_loss: 0.9784 - val_accuracy: 0.2903\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9334 - accuracy: 0.3710 - val_loss: 0.9768 - val_accuracy: 0.3226\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9320 - accuracy: 0.3710 - val_loss: 0.9753 - val_accuracy: 0.2903\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9308 - accuracy: 0.3871 - val_loss: 0.9738 - val_accuracy: 0.3548\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9294 - accuracy: 0.3871 - val_loss: 0.9721 - val_accuracy: 0.3548\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9280 - accuracy: 0.4032 - val_loss: 0.9706 - val_accuracy: 0.3548\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9267 - accuracy: 0.4194 - val_loss: 0.9691 - val_accuracy: 0.4194\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9253 - accuracy: 0.4194 - val_loss: 0.9673 - val_accuracy: 0.4194\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9241 - accuracy: 0.4274 - val_loss: 0.9656 - val_accuracy: 0.4516\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9227 - accuracy: 0.4516 - val_loss: 0.9641 - val_accuracy: 0.4839\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9215 - accuracy: 0.4597 - val_loss: 0.9627 - val_accuracy: 0.4839\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9200 - accuracy: 0.4758 - val_loss: 0.9611 - val_accuracy: 0.4839\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9188 - accuracy: 0.5000 - val_loss: 0.9593 - val_accuracy: 0.5484\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9177 - accuracy: 0.5403 - val_loss: 0.9574 - val_accuracy: 0.6452\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9162 - accuracy: 0.5806 - val_loss: 0.9558 - val_accuracy: 0.7097\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9148 - accuracy: 0.6290 - val_loss: 0.9543 - val_accuracy: 0.7419\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9136 - accuracy: 0.6532 - val_loss: 0.9528 - val_accuracy: 0.7419\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9122 - accuracy: 0.6613 - val_loss: 0.9511 - val_accuracy: 0.7742\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9109 - accuracy: 0.7097 - val_loss: 0.9495 - val_accuracy: 0.7742\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9097 - accuracy: 0.7097 - val_loss: 0.9480 - val_accuracy: 0.7742\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9083 - accuracy: 0.7016 - val_loss: 0.9464 - val_accuracy: 0.7742\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9071 - accuracy: 0.7097 - val_loss: 0.9449 - val_accuracy: 0.7742\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9057 - accuracy: 0.7339 - val_loss: 0.9432 - val_accuracy: 0.7742\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9044 - accuracy: 0.7339 - val_loss: 0.9416 - val_accuracy: 0.7742\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9031 - accuracy: 0.7339 - val_loss: 0.9399 - val_accuracy: 0.7742\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9019 - accuracy: 0.7339 - val_loss: 0.9383 - val_accuracy: 0.7742\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.9005 - accuracy: 0.7500 - val_loss: 0.9365 - val_accuracy: 0.7742\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8992 - accuracy: 0.7500 - val_loss: 0.9349 - val_accuracy: 0.7742\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8979 - accuracy: 0.7581 - val_loss: 0.9331 - val_accuracy: 0.7742\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8966 - accuracy: 0.7500 - val_loss: 0.9314 - val_accuracy: 0.7742\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8953 - accuracy: 0.7581 - val_loss: 0.9297 - val_accuracy: 0.7742\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8939 - accuracy: 0.7661 - val_loss: 0.9281 - val_accuracy: 0.7742\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8926 - accuracy: 0.7661 - val_loss: 0.9266 - val_accuracy: 0.7742\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8913 - accuracy: 0.7661 - val_loss: 0.9251 - val_accuracy: 0.7742\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8900 - accuracy: 0.7661 - val_loss: 0.9234 - val_accuracy: 0.7742\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8887 - accuracy: 0.7661 - val_loss: 0.9219 - val_accuracy: 0.7742\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8873 - accuracy: 0.7661 - val_loss: 0.9201 - val_accuracy: 0.7742\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8859 - accuracy: 0.7661 - val_loss: 0.9183 - val_accuracy: 0.7742\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8846 - accuracy: 0.7661 - val_loss: 0.9166 - val_accuracy: 0.7742\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8833 - accuracy: 0.7661 - val_loss: 0.9148 - val_accuracy: 0.7742\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8820 - accuracy: 0.7742 - val_loss: 0.9130 - val_accuracy: 0.7742\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8805 - accuracy: 0.7661 - val_loss: 0.9114 - val_accuracy: 0.7742\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8793 - accuracy: 0.7661 - val_loss: 0.9096 - val_accuracy: 0.7742\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8778 - accuracy: 0.7742 - val_loss: 0.9078 - val_accuracy: 0.7742\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8766 - accuracy: 0.7742 - val_loss: 0.9060 - val_accuracy: 0.7742\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8751 - accuracy: 0.7742 - val_loss: 0.9044 - val_accuracy: 0.7742\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8738 - accuracy: 0.7742 - val_loss: 0.9026 - val_accuracy: 0.7742\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8724 - accuracy: 0.7742 - val_loss: 0.9011 - val_accuracy: 0.7742\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8711 - accuracy: 0.7742 - val_loss: 0.8992 - val_accuracy: 0.7742\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8696 - accuracy: 0.7742 - val_loss: 0.8975 - val_accuracy: 0.8065\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8683 - accuracy: 0.7742 - val_loss: 0.8957 - val_accuracy: 0.8065\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8668 - accuracy: 0.7742 - val_loss: 0.8941 - val_accuracy: 0.8065\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8655 - accuracy: 0.7742 - val_loss: 0.8923 - val_accuracy: 0.8065\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8641 - accuracy: 0.7742 - val_loss: 0.8905 - val_accuracy: 0.8065\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8626 - accuracy: 0.7742 - val_loss: 0.8889 - val_accuracy: 0.8065\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8613 - accuracy: 0.7742 - val_loss: 0.8872 - val_accuracy: 0.8065\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8599 - accuracy: 0.7742 - val_loss: 0.8854 - val_accuracy: 0.8065\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8584 - accuracy: 0.7742 - val_loss: 0.8837 - val_accuracy: 0.8065\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8570 - accuracy: 0.7742 - val_loss: 0.8818 - val_accuracy: 0.8065\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8556 - accuracy: 0.7742 - val_loss: 0.8799 - val_accuracy: 0.8065\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8541 - accuracy: 0.7742 - val_loss: 0.8782 - val_accuracy: 0.8065\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8528 - accuracy: 0.7823 - val_loss: 0.8767 - val_accuracy: 0.7742\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8513 - accuracy: 0.7823 - val_loss: 0.8747 - val_accuracy: 0.8065\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8498 - accuracy: 0.7823 - val_loss: 0.8729 - val_accuracy: 0.8065\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8485 - accuracy: 0.7823 - val_loss: 0.8709 - val_accuracy: 0.8065\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8468 - accuracy: 0.7823 - val_loss: 0.8691 - val_accuracy: 0.8065\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8454 - accuracy: 0.7823 - val_loss: 0.8673 - val_accuracy: 0.8065\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8439 - accuracy: 0.7823 - val_loss: 0.8654 - val_accuracy: 0.8065\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8424 - accuracy: 0.7823 - val_loss: 0.8637 - val_accuracy: 0.8065\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8410 - accuracy: 0.7903 - val_loss: 0.8616 - val_accuracy: 0.8065\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8395 - accuracy: 0.7903 - val_loss: 0.8596 - val_accuracy: 0.8065\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8380 - accuracy: 0.7823 - val_loss: 0.8575 - val_accuracy: 0.8065\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8364 - accuracy: 0.7823 - val_loss: 0.8556 - val_accuracy: 0.8065\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8349 - accuracy: 0.7823 - val_loss: 0.8538 - val_accuracy: 0.8065\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8334 - accuracy: 0.7823 - val_loss: 0.8518 - val_accuracy: 0.8065\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8318 - accuracy: 0.7823 - val_loss: 0.8501 - val_accuracy: 0.8065\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8303 - accuracy: 0.7903 - val_loss: 0.8482 - val_accuracy: 0.8065\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8288 - accuracy: 0.7742 - val_loss: 0.8462 - val_accuracy: 0.8065\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8272 - accuracy: 0.7742 - val_loss: 0.8443 - val_accuracy: 0.8065\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8256 - accuracy: 0.7823 - val_loss: 0.8426 - val_accuracy: 0.8065\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8241 - accuracy: 0.7823 - val_loss: 0.8406 - val_accuracy: 0.8065\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8225 - accuracy: 0.7823 - val_loss: 0.8386 - val_accuracy: 0.8065\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8209 - accuracy: 0.7823 - val_loss: 0.8365 - val_accuracy: 0.8065\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8194 - accuracy: 0.7742 - val_loss: 0.8343 - val_accuracy: 0.8065\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8177 - accuracy: 0.7742 - val_loss: 0.8323 - val_accuracy: 0.8065\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8162 - accuracy: 0.7742 - val_loss: 0.8304 - val_accuracy: 0.8065\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8146 - accuracy: 0.7661 - val_loss: 0.8282 - val_accuracy: 0.8065\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8129 - accuracy: 0.7742 - val_loss: 0.8262 - val_accuracy: 0.8065\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8113 - accuracy: 0.7823 - val_loss: 0.8244 - val_accuracy: 0.8065\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8097 - accuracy: 0.7742 - val_loss: 0.8223 - val_accuracy: 0.8065\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8081 - accuracy: 0.7742 - val_loss: 0.8204 - val_accuracy: 0.8065\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8064 - accuracy: 0.7742 - val_loss: 0.8185 - val_accuracy: 0.8065\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8049 - accuracy: 0.7742 - val_loss: 0.8167 - val_accuracy: 0.8065\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8034 - accuracy: 0.7742 - val_loss: 0.8144 - val_accuracy: 0.8065\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.8015 - accuracy: 0.7742 - val_loss: 0.8123 - val_accuracy: 0.8065\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7999 - accuracy: 0.7742 - val_loss: 0.8103 - val_accuracy: 0.8065\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7982 - accuracy: 0.7742 - val_loss: 0.8083 - val_accuracy: 0.8065\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7967 - accuracy: 0.7742 - val_loss: 0.8065 - val_accuracy: 0.8065\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7949 - accuracy: 0.7742 - val_loss: 0.8043 - val_accuracy: 0.8065\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7932 - accuracy: 0.7742 - val_loss: 0.8024 - val_accuracy: 0.8065\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7916 - accuracy: 0.7742 - val_loss: 0.8003 - val_accuracy: 0.8065\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7899 - accuracy: 0.7742 - val_loss: 0.7983 - val_accuracy: 0.8065\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7882 - accuracy: 0.7742 - val_loss: 0.7961 - val_accuracy: 0.8065\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7865 - accuracy: 0.7742 - val_loss: 0.7942 - val_accuracy: 0.8065\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7848 - accuracy: 0.7742 - val_loss: 0.7924 - val_accuracy: 0.8065\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7831 - accuracy: 0.7742 - val_loss: 0.7903 - val_accuracy: 0.8065\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7814 - accuracy: 0.7742 - val_loss: 0.7883 - val_accuracy: 0.8065\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7799 - accuracy: 0.7742 - val_loss: 0.7860 - val_accuracy: 0.8065\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7780 - accuracy: 0.7742 - val_loss: 0.7840 - val_accuracy: 0.8065\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7763 - accuracy: 0.7742 - val_loss: 0.7821 - val_accuracy: 0.8065\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7745 - accuracy: 0.7742 - val_loss: 0.7800 - val_accuracy: 0.8065\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7728 - accuracy: 0.7742 - val_loss: 0.7780 - val_accuracy: 0.8065\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7712 - accuracy: 0.7742 - val_loss: 0.7759 - val_accuracy: 0.8065\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7694 - accuracy: 0.7742 - val_loss: 0.7738 - val_accuracy: 0.8065\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7677 - accuracy: 0.7742 - val_loss: 0.7720 - val_accuracy: 0.8065\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7660 - accuracy: 0.7742 - val_loss: 0.7700 - val_accuracy: 0.8065\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7641 - accuracy: 0.7742 - val_loss: 0.7679 - val_accuracy: 0.8065\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7626 - accuracy: 0.7742 - val_loss: 0.7656 - val_accuracy: 0.8065\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7608 - accuracy: 0.7742 - val_loss: 0.7636 - val_accuracy: 0.8065\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7590 - accuracy: 0.7742 - val_loss: 0.7615 - val_accuracy: 0.8065\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7572 - accuracy: 0.7742 - val_loss: 0.7593 - val_accuracy: 0.8065\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7554 - accuracy: 0.7742 - val_loss: 0.7572 - val_accuracy: 0.8065\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7537 - accuracy: 0.7742 - val_loss: 0.7552 - val_accuracy: 0.8065\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7520 - accuracy: 0.7742 - val_loss: 0.7530 - val_accuracy: 0.8387\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7503 - accuracy: 0.7742 - val_loss: 0.7511 - val_accuracy: 0.8065\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7484 - accuracy: 0.7742 - val_loss: 0.7491 - val_accuracy: 0.8065\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7468 - accuracy: 0.7742 - val_loss: 0.7467 - val_accuracy: 0.8387\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7449 - accuracy: 0.7742 - val_loss: 0.7448 - val_accuracy: 0.8387\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7432 - accuracy: 0.7742 - val_loss: 0.7428 - val_accuracy: 0.8065\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7414 - accuracy: 0.7742 - val_loss: 0.7408 - val_accuracy: 0.8065\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7396 - accuracy: 0.7742 - val_loss: 0.7388 - val_accuracy: 0.8065\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7379 - accuracy: 0.7742 - val_loss: 0.7367 - val_accuracy: 0.8065\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7361 - accuracy: 0.7742 - val_loss: 0.7346 - val_accuracy: 0.8065\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7344 - accuracy: 0.7742 - val_loss: 0.7327 - val_accuracy: 0.8065\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7326 - accuracy: 0.7742 - val_loss: 0.7306 - val_accuracy: 0.8065\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7308 - accuracy: 0.7742 - val_loss: 0.7285 - val_accuracy: 0.8065\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7290 - accuracy: 0.7742 - val_loss: 0.7265 - val_accuracy: 0.8065\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7274 - accuracy: 0.7742 - val_loss: 0.7243 - val_accuracy: 0.8065\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7255 - accuracy: 0.7742 - val_loss: 0.7224 - val_accuracy: 0.8065\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7237 - accuracy: 0.7742 - val_loss: 0.7204 - val_accuracy: 0.8065\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7220 - accuracy: 0.7742 - val_loss: 0.7186 - val_accuracy: 0.8065\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7203 - accuracy: 0.7742 - val_loss: 0.7165 - val_accuracy: 0.8065\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7184 - accuracy: 0.7742 - val_loss: 0.7146 - val_accuracy: 0.8065\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7167 - accuracy: 0.7742 - val_loss: 0.7124 - val_accuracy: 0.8065\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7150 - accuracy: 0.7742 - val_loss: 0.7105 - val_accuracy: 0.8065\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7131 - accuracy: 0.7742 - val_loss: 0.7086 - val_accuracy: 0.8065\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.7114 - accuracy: 0.7742 - val_loss: 0.7065 - val_accuracy: 0.8065\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7096 - accuracy: 0.7742 - val_loss: 0.7047 - val_accuracy: 0.8065\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7078 - accuracy: 0.7742 - val_loss: 0.7027 - val_accuracy: 0.8065\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7061 - accuracy: 0.7742 - val_loss: 0.7008 - val_accuracy: 0.8065\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7043 - accuracy: 0.7742 - val_loss: 0.6988 - val_accuracy: 0.8065\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7027 - accuracy: 0.7742 - val_loss: 0.6965 - val_accuracy: 0.8065\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.7742 - val_loss: 0.6947 - val_accuracy: 0.8065\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6990 - accuracy: 0.7742 - val_loss: 0.6926 - val_accuracy: 0.8065\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.7742 - val_loss: 0.6906 - val_accuracy: 0.8387\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6955 - accuracy: 0.7742 - val_loss: 0.6888 - val_accuracy: 0.8065\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.7742 - val_loss: 0.6869 - val_accuracy: 0.8065\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6921 - accuracy: 0.7742 - val_loss: 0.6852 - val_accuracy: 0.8065\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6904 - accuracy: 0.7742 - val_loss: 0.6833 - val_accuracy: 0.8065\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6886 - accuracy: 0.7742 - val_loss: 0.6816 - val_accuracy: 0.8065\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.7742 - val_loss: 0.6797 - val_accuracy: 0.8065\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6852 - accuracy: 0.7742 - val_loss: 0.6778 - val_accuracy: 0.8065\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6835 - accuracy: 0.7742 - val_loss: 0.6760 - val_accuracy: 0.8065\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6818 - accuracy: 0.7742 - val_loss: 0.6742 - val_accuracy: 0.8065\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6802 - accuracy: 0.7742 - val_loss: 0.6726 - val_accuracy: 0.8065\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.7742 - val_loss: 0.6707 - val_accuracy: 0.8065\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.7742 - val_loss: 0.6689 - val_accuracy: 0.8065\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6750 - accuracy: 0.7742 - val_loss: 0.6671 - val_accuracy: 0.8065\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6734 - accuracy: 0.7742 - val_loss: 0.6653 - val_accuracy: 0.8065\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6717 - accuracy: 0.7742 - val_loss: 0.6637 - val_accuracy: 0.8065\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6701 - accuracy: 0.7742 - val_loss: 0.6618 - val_accuracy: 0.8065\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6685 - accuracy: 0.7742 - val_loss: 0.6602 - val_accuracy: 0.8065\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.7742 - val_loss: 0.6584 - val_accuracy: 0.8065\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6651 - accuracy: 0.7742 - val_loss: 0.6569 - val_accuracy: 0.8065\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6634 - accuracy: 0.7742 - val_loss: 0.6553 - val_accuracy: 0.8065\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6619 - accuracy: 0.7742 - val_loss: 0.6535 - val_accuracy: 0.8065\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6602 - accuracy: 0.7742 - val_loss: 0.6520 - val_accuracy: 0.8065\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6587 - accuracy: 0.7742 - val_loss: 0.6502 - val_accuracy: 0.8065\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6570 - accuracy: 0.7742 - val_loss: 0.6485 - val_accuracy: 0.8065\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6553 - accuracy: 0.7742 - val_loss: 0.6470 - val_accuracy: 0.8065\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6539 - accuracy: 0.7742 - val_loss: 0.6451 - val_accuracy: 0.8065\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6522 - accuracy: 0.7742 - val_loss: 0.6434 - val_accuracy: 0.8065\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6507 - accuracy: 0.7742 - val_loss: 0.6420 - val_accuracy: 0.8065\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6490 - accuracy: 0.7742 - val_loss: 0.6405 - val_accuracy: 0.8065\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6475 - accuracy: 0.7742 - val_loss: 0.6389 - val_accuracy: 0.8065\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6459 - accuracy: 0.7742 - val_loss: 0.6373 - val_accuracy: 0.8065\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6444 - accuracy: 0.7742 - val_loss: 0.6357 - val_accuracy: 0.8065\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6428 - accuracy: 0.7742 - val_loss: 0.6343 - val_accuracy: 0.8065\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6414 - accuracy: 0.7742 - val_loss: 0.6328 - val_accuracy: 0.8065\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6398 - accuracy: 0.7742 - val_loss: 0.6312 - val_accuracy: 0.8065\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6384 - accuracy: 0.7742 - val_loss: 0.6296 - val_accuracy: 0.8065\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6368 - accuracy: 0.7742 - val_loss: 0.6283 - val_accuracy: 0.8065\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6352 - accuracy: 0.7742 - val_loss: 0.6270 - val_accuracy: 0.8065\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6338 - accuracy: 0.7742 - val_loss: 0.6258 - val_accuracy: 0.8065\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6323 - accuracy: 0.7742 - val_loss: 0.6244 - val_accuracy: 0.8065\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6310 - accuracy: 0.7742 - val_loss: 0.6231 - val_accuracy: 0.8065\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6294 - accuracy: 0.7742 - val_loss: 0.6215 - val_accuracy: 0.8065\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6279 - accuracy: 0.7742 - val_loss: 0.6202 - val_accuracy: 0.8065\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6265 - accuracy: 0.7742 - val_loss: 0.6188 - val_accuracy: 0.8065\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6251 - accuracy: 0.7742 - val_loss: 0.6173 - val_accuracy: 0.8065\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.7742 - val_loss: 0.6160 - val_accuracy: 0.8065\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6222 - accuracy: 0.7742 - val_loss: 0.6146 - val_accuracy: 0.8065\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6208 - accuracy: 0.7742 - val_loss: 0.6133 - val_accuracy: 0.8065\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6194 - accuracy: 0.7742 - val_loss: 0.6121 - val_accuracy: 0.8065\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6181 - accuracy: 0.7742 - val_loss: 0.6106 - val_accuracy: 0.8065\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6166 - accuracy: 0.7742 - val_loss: 0.6095 - val_accuracy: 0.8065\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.7742 - val_loss: 0.6083 - val_accuracy: 0.8065\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6140 - accuracy: 0.7742 - val_loss: 0.6072 - val_accuracy: 0.8065\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6126 - accuracy: 0.7742 - val_loss: 0.6058 - val_accuracy: 0.8065\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6112 - accuracy: 0.7742 - val_loss: 0.6046 - val_accuracy: 0.8065\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6100 - accuracy: 0.7742 - val_loss: 0.6035 - val_accuracy: 0.8065\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6085 - accuracy: 0.7742 - val_loss: 0.6024 - val_accuracy: 0.8065\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6073 - accuracy: 0.7742 - val_loss: 0.6014 - val_accuracy: 0.8065\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6060 - accuracy: 0.7742 - val_loss: 0.6003 - val_accuracy: 0.8065\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.7742 - val_loss: 0.5992 - val_accuracy: 0.8065\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6035 - accuracy: 0.7742 - val_loss: 0.5979 - val_accuracy: 0.8065\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6022 - accuracy: 0.7742 - val_loss: 0.5971 - val_accuracy: 0.8065\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.7742 - val_loss: 0.5961 - val_accuracy: 0.8065\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5996 - accuracy: 0.7742 - val_loss: 0.5950 - val_accuracy: 0.8065\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5983 - accuracy: 0.7742 - val_loss: 0.5941 - val_accuracy: 0.8065\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.7742 - val_loss: 0.5933 - val_accuracy: 0.8065\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5959 - accuracy: 0.7742 - val_loss: 0.5921 - val_accuracy: 0.8065\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5947 - accuracy: 0.7742 - val_loss: 0.5913 - val_accuracy: 0.8065\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5936 - accuracy: 0.7742 - val_loss: 0.5898 - val_accuracy: 0.8065\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5924 - accuracy: 0.7742 - val_loss: 0.5886 - val_accuracy: 0.8065\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5911 - accuracy: 0.7742 - val_loss: 0.5876 - val_accuracy: 0.8065\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5898 - accuracy: 0.7742 - val_loss: 0.5867 - val_accuracy: 0.8065\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.7742 - val_loss: 0.5860 - val_accuracy: 0.8065\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.7742 - val_loss: 0.5852 - val_accuracy: 0.8065\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5865 - accuracy: 0.7742 - val_loss: 0.5842 - val_accuracy: 0.8065\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5853 - accuracy: 0.7742 - val_loss: 0.5835 - val_accuracy: 0.8065\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5842 - accuracy: 0.7742 - val_loss: 0.5827 - val_accuracy: 0.8065\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5830 - accuracy: 0.7742 - val_loss: 0.5818 - val_accuracy: 0.8065\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5821 - accuracy: 0.7742 - val_loss: 0.5809 - val_accuracy: 0.8065\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5809 - accuracy: 0.7742 - val_loss: 0.5802 - val_accuracy: 0.8065\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5799 - accuracy: 0.7742 - val_loss: 0.5794 - val_accuracy: 0.8065\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5788 - accuracy: 0.7742 - val_loss: 0.5785 - val_accuracy: 0.8065\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5777 - accuracy: 0.7742 - val_loss: 0.5779 - val_accuracy: 0.8065\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5767 - accuracy: 0.7742 - val_loss: 0.5772 - val_accuracy: 0.8065\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5757 - accuracy: 0.7742 - val_loss: 0.5763 - val_accuracy: 0.8065\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.7742 - val_loss: 0.5758 - val_accuracy: 0.8065\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5735 - accuracy: 0.7661 - val_loss: 0.5749 - val_accuracy: 0.8065\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5727 - accuracy: 0.7742 - val_loss: 0.5740 - val_accuracy: 0.8065\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5718 - accuracy: 0.7661 - val_loss: 0.5736 - val_accuracy: 0.8065\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5706 - accuracy: 0.7661 - val_loss: 0.5727 - val_accuracy: 0.8065\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.7742 - val_loss: 0.5721 - val_accuracy: 0.8065\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.7661 - val_loss: 0.5714 - val_accuracy: 0.8065\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5677 - accuracy: 0.7742 - val_loss: 0.5705 - val_accuracy: 0.8065\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5666 - accuracy: 0.7742 - val_loss: 0.5699 - val_accuracy: 0.8065\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5657 - accuracy: 0.7742 - val_loss: 0.5691 - val_accuracy: 0.8065\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5647 - accuracy: 0.7742 - val_loss: 0.5685 - val_accuracy: 0.8065\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5640 - accuracy: 0.7742 - val_loss: 0.5677 - val_accuracy: 0.8065\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5630 - accuracy: 0.7742 - val_loss: 0.5674 - val_accuracy: 0.8065\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5620 - accuracy: 0.7742 - val_loss: 0.5668 - val_accuracy: 0.8065\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5612 - accuracy: 0.7742 - val_loss: 0.5663 - val_accuracy: 0.8065\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5603 - accuracy: 0.7742 - val_loss: 0.5656 - val_accuracy: 0.8065\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.7742 - val_loss: 0.5651 - val_accuracy: 0.8065\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5584 - accuracy: 0.7742 - val_loss: 0.5644 - val_accuracy: 0.8065\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7742 - val_loss: 0.5639 - val_accuracy: 0.8065\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7742 - val_loss: 0.5634 - val_accuracy: 0.8065\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5561 - accuracy: 0.7742 - val_loss: 0.5627 - val_accuracy: 0.8065\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.7661 - val_loss: 0.5626 - val_accuracy: 0.8065\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7661 - val_loss: 0.5623 - val_accuracy: 0.8065\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5534 - accuracy: 0.7661 - val_loss: 0.5620 - val_accuracy: 0.8065\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5525 - accuracy: 0.7581 - val_loss: 0.5615 - val_accuracy: 0.8065\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5519 - accuracy: 0.7661 - val_loss: 0.5608 - val_accuracy: 0.8065\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7581 - val_loss: 0.5605 - val_accuracy: 0.8065\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5502 - accuracy: 0.7581 - val_loss: 0.5602 - val_accuracy: 0.8065\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5494 - accuracy: 0.7500 - val_loss: 0.5599 - val_accuracy: 0.8065\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.7581 - val_loss: 0.5592 - val_accuracy: 0.8065\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.7581 - val_loss: 0.5586 - val_accuracy: 0.8065\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7581 - val_loss: 0.5583 - val_accuracy: 0.8065\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7581 - val_loss: 0.5575 - val_accuracy: 0.8065\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5457 - accuracy: 0.7661 - val_loss: 0.5570 - val_accuracy: 0.8065\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5450 - accuracy: 0.7661 - val_loss: 0.5570 - val_accuracy: 0.8065\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5441 - accuracy: 0.7581 - val_loss: 0.5567 - val_accuracy: 0.8065\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7581 - val_loss: 0.5562 - val_accuracy: 0.8065\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5427 - accuracy: 0.7581 - val_loss: 0.5557 - val_accuracy: 0.8065\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7581 - val_loss: 0.5554 - val_accuracy: 0.8065\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7581 - val_loss: 0.5551 - val_accuracy: 0.8065\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7581 - val_loss: 0.5546 - val_accuracy: 0.8065\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5400 - accuracy: 0.7661 - val_loss: 0.5543 - val_accuracy: 0.8065\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5392 - accuracy: 0.7581 - val_loss: 0.5543 - val_accuracy: 0.8065\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7581 - val_loss: 0.5543 - val_accuracy: 0.8065\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5379 - accuracy: 0.7500 - val_loss: 0.5541 - val_accuracy: 0.8065\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5373 - accuracy: 0.7500 - val_loss: 0.5539 - val_accuracy: 0.8065\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7500 - val_loss: 0.5537 - val_accuracy: 0.8065\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7500 - val_loss: 0.5533 - val_accuracy: 0.8065\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5355 - accuracy: 0.7500 - val_loss: 0.5531 - val_accuracy: 0.8065\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7500 - val_loss: 0.5529 - val_accuracy: 0.8065\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7500 - val_loss: 0.5525 - val_accuracy: 0.8065\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5336 - accuracy: 0.7581 - val_loss: 0.5520 - val_accuracy: 0.8065\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7581 - val_loss: 0.5516 - val_accuracy: 0.8065\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7581 - val_loss: 0.5515 - val_accuracy: 0.8065\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7500 - val_loss: 0.5515 - val_accuracy: 0.8065\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7581 - val_loss: 0.5510 - val_accuracy: 0.8065\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7581 - val_loss: 0.5510 - val_accuracy: 0.8065\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7581 - val_loss: 0.5505 - val_accuracy: 0.8065\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7581 - val_loss: 0.5500 - val_accuracy: 0.8065\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7581 - val_loss: 0.5500 - val_accuracy: 0.8065\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5284 - accuracy: 0.7581 - val_loss: 0.5497 - val_accuracy: 0.8065\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5278 - accuracy: 0.7581 - val_loss: 0.5495 - val_accuracy: 0.8065\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7581 - val_loss: 0.5496 - val_accuracy: 0.8065\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7581 - val_loss: 0.5494 - val_accuracy: 0.8065\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7581 - val_loss: 0.5493 - val_accuracy: 0.8065\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7581 - val_loss: 0.5492 - val_accuracy: 0.8065\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7581 - val_loss: 0.5492 - val_accuracy: 0.8065\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5247 - accuracy: 0.7581 - val_loss: 0.5490 - val_accuracy: 0.8065\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7581 - val_loss: 0.5488 - val_accuracy: 0.8065\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5237 - accuracy: 0.7581 - val_loss: 0.5490 - val_accuracy: 0.8065\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7581 - val_loss: 0.5490 - val_accuracy: 0.8065\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5227 - accuracy: 0.7581 - val_loss: 0.5489 - val_accuracy: 0.8065\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5223 - accuracy: 0.7581 - val_loss: 0.5491 - val_accuracy: 0.8065\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5220 - accuracy: 0.7419 - val_loss: 0.5493 - val_accuracy: 0.8065\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7419 - val_loss: 0.5489 - val_accuracy: 0.8065\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7419 - val_loss: 0.5486 - val_accuracy: 0.8065\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5204 - accuracy: 0.7419 - val_loss: 0.5486 - val_accuracy: 0.8065\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5199 - accuracy: 0.7500 - val_loss: 0.5484 - val_accuracy: 0.7742\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7419 - val_loss: 0.5484 - val_accuracy: 0.7742\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7419 - val_loss: 0.5483 - val_accuracy: 0.7742\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7419 - val_loss: 0.5484 - val_accuracy: 0.7742\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.7419 - val_loss: 0.5483 - val_accuracy: 0.7742\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7500 - val_loss: 0.5477 - val_accuracy: 0.7742\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7500 - val_loss: 0.5475 - val_accuracy: 0.7742\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7742\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7500 - val_loss: 0.5473 - val_accuracy: 0.7742\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5163 - accuracy: 0.7500 - val_loss: 0.5475 - val_accuracy: 0.7742\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7742\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5155 - accuracy: 0.7500 - val_loss: 0.5473 - val_accuracy: 0.7742\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.7500 - val_loss: 0.5474 - val_accuracy: 0.7742\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7500 - val_loss: 0.5474 - val_accuracy: 0.7742\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7742\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5139 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7742\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7419 - val_loss: 0.5479 - val_accuracy: 0.7742\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7419 - val_loss: 0.5477 - val_accuracy: 0.7742\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7742\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7742\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7500 - val_loss: 0.5474 - val_accuracy: 0.7742\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7500 - val_loss: 0.5473 - val_accuracy: 0.7742\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7500 - val_loss: 0.5473 - val_accuracy: 0.7742\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5114 - accuracy: 0.7419 - val_loss: 0.5477 - val_accuracy: 0.7742\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7419 - val_loss: 0.5478 - val_accuracy: 0.7742\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5105 - accuracy: 0.7419 - val_loss: 0.5480 - val_accuracy: 0.7742\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.7419 - val_loss: 0.5479 - val_accuracy: 0.7742\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7419 - val_loss: 0.5479 - val_accuracy: 0.7742\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5095 - accuracy: 0.7419 - val_loss: 0.5478 - val_accuracy: 0.7742\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5094 - accuracy: 0.7500 - val_loss: 0.5475 - val_accuracy: 0.7742\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5089 - accuracy: 0.7500 - val_loss: 0.5475 - val_accuracy: 0.7742\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5086 - accuracy: 0.7500 - val_loss: 0.5478 - val_accuracy: 0.7742\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5083 - accuracy: 0.7419 - val_loss: 0.5482 - val_accuracy: 0.7742\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5080 - accuracy: 0.7419 - val_loss: 0.5482 - val_accuracy: 0.7742\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7419 - val_loss: 0.5484 - val_accuracy: 0.7742\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7419 - val_loss: 0.5485 - val_accuracy: 0.8065\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7419 - val_loss: 0.5486 - val_accuracy: 0.8065\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7419 - val_loss: 0.5486 - val_accuracy: 0.8065\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.7419 - val_loss: 0.5486 - val_accuracy: 0.8065\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.7419 - val_loss: 0.5487 - val_accuracy: 0.8065\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7419 - val_loss: 0.5489 - val_accuracy: 0.8065\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.7419 - val_loss: 0.5488 - val_accuracy: 0.8065\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5056 - accuracy: 0.7419 - val_loss: 0.5488 - val_accuracy: 0.8065\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7419 - val_loss: 0.5489 - val_accuracy: 0.8065\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7419 - val_loss: 0.5488 - val_accuracy: 0.8065\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7500 - val_loss: 0.5489 - val_accuracy: 0.8065\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5047 - accuracy: 0.7419 - val_loss: 0.5486 - val_accuracy: 0.8065\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.7500 - val_loss: 0.5488 - val_accuracy: 0.8065\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7500 - val_loss: 0.5488 - val_accuracy: 0.8065\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7500 - val_loss: 0.5492 - val_accuracy: 0.8065\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7500 - val_loss: 0.5490 - val_accuracy: 0.8065\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7581 - val_loss: 0.5492 - val_accuracy: 0.8065\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5033 - accuracy: 0.7581 - val_loss: 0.5492 - val_accuracy: 0.8065\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7581 - val_loss: 0.5494 - val_accuracy: 0.8065\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7500 - val_loss: 0.5495 - val_accuracy: 0.8065\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5026 - accuracy: 0.7581 - val_loss: 0.5495 - val_accuracy: 0.8065\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5024 - accuracy: 0.7581 - val_loss: 0.5496 - val_accuracy: 0.8065\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5021 - accuracy: 0.7581 - val_loss: 0.5495 - val_accuracy: 0.8065\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5020 - accuracy: 0.7581 - val_loss: 0.5496 - val_accuracy: 0.8065\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.7581 - val_loss: 0.5499 - val_accuracy: 0.8065\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.7500 - val_loss: 0.5502 - val_accuracy: 0.8065\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.7500 - val_loss: 0.5499 - val_accuracy: 0.8065\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7581 - val_loss: 0.5498 - val_accuracy: 0.8065\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7581 - val_loss: 0.5500 - val_accuracy: 0.8065\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5008 - accuracy: 0.7581 - val_loss: 0.5505 - val_accuracy: 0.8065\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7500 - val_loss: 0.5505 - val_accuracy: 0.8065\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7500 - val_loss: 0.5509 - val_accuracy: 0.8065\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7500 - val_loss: 0.5511 - val_accuracy: 0.8065\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.7500 - val_loss: 0.5511 - val_accuracy: 0.8065\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7500 - val_loss: 0.5515 - val_accuracy: 0.8065\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7500 - val_loss: 0.5510 - val_accuracy: 0.8065\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.7500 - val_loss: 0.5512 - val_accuracy: 0.8065\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7581 - val_loss: 0.5513 - val_accuracy: 0.8065\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7581 - val_loss: 0.5515 - val_accuracy: 0.8065\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7581 - val_loss: 0.5517 - val_accuracy: 0.8065\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7581 - val_loss: 0.5518 - val_accuracy: 0.8065\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7581 - val_loss: 0.5516 - val_accuracy: 0.8065\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7661 - val_loss: 0.5514 - val_accuracy: 0.8065\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4985 - accuracy: 0.7661 - val_loss: 0.5518 - val_accuracy: 0.8065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20677887040>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Configuração de parâmetros da rede neural (adam = algoritmo de ajuste de pesos, loss = cálculo do erro)\n",
    "modelo.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#Treinamento, dividindo a base de treino com uma porção para validação (validation_data)\n",
    "modelo.fit(X_treino, y_treino, epochs = 500, \n",
    "           validation_data = (X_teste, y_teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testando o modelo com os dados de teste\n",
    "previsoes = modelo.predict(X_teste)\n",
    "previsoes = (previsoes > 0.5)\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Precisamos criar uma Matriz de Confusão para comparar a taxa \n",
    "de acerto das previsoes, para isso é necessário passar os dados \n",
    "reais de teste(y_teste) para uma variável(y_teste_matriz) e os \n",
    "dados das previsões para a variável(y_previsão_matriz)\n",
    "'''\n",
    "y_teste_matriz = [np.argmax(t) for t in y_teste]\n",
    "y_previsao_matriz = [np.argmax(t) for t in previsoes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12,  0,  1],\n",
       "       [ 0,  1,  3],\n",
       "       [ 0,  1, 13]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Criando a Matriz de Confusão para verificar a taxa de acerto\n",
    "confusao = confusion_matrix(y_teste_matriz, y_previsao_matriz)\n",
    "confusao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8387096774193549"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando a taxa de acerto das previsoes\n",
    "taxa_acerto = accuracy_score(y_teste_matriz, y_previsao_matriz)\n",
    "taxa_acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando o modelo com pickle\n",
    "#pickle.dump(modelo, open('modelo.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando o modelo em formato .h5\n",
    "#path = 'modelo.h5'\n",
    "#modelo.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função de previsão\n",
    "def prever(x):\n",
    "    previsao = modelo.predict(x)\n",
    "    if previsao[:,0] > 0.50:\n",
    "        print('O IDH tende a ser ALTO!')\n",
    "    elif previsao[:,1] > 0.50:\n",
    "        print('O IDH tende a ser BAIXO!')\n",
    "    else:\n",
    "        print('O IDH tende a ser MÉDIO!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "O IDH tende a ser MÉDIO!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Não podemos prever novos dados utilizando os dados reais de ILE e IPC\n",
    "porque nosso modelo foi construído com base em dados normalizados, sendo \n",
    "assim, precisamos passar para o modelo o dado normalizado correspondente \n",
    "ao dado real inserido pelo usuário e, caso um dado inserido não exista, \n",
    "então teremos que atualizar a lista previsores e em seguida normalizar \n",
    "essa lista atualizada.\n",
    "'''\n",
    "#Novos dados\n",
    "ile = 6.63\n",
    "ipc = 35\n",
    "#Array dos novos dados\n",
    "novo = [[ile, ipc]]\n",
    "#Laço para percorrer a lista previsores\n",
    "for i in range(len(previsores)):\n",
    "    cont = i + 1\n",
    "    #Lógica para verificar se os novos dados já existem na lista previsores\n",
    "    if np.all(novo[0] == previsores[i]):\n",
    "        #Se existirem, a variável x recupera os dados normalizados na lista normalizados\n",
    "        x = np.array([normalizados[i]])\n",
    "        #Realizando a nova previsão\n",
    "        prever(x)\n",
    "        break\n",
    "    #Se o contador finalizar a lista, significa que os dados novos ainda não existem\n",
    "    #Se isso ocorrer precisamos atualizar a lista previsores e a lista normalizados\n",
    "    else:\n",
    "        cont == len(previsores)\n",
    "        #Atualizando a lista previsores, inserindo os novos dados\n",
    "        previsores = np.append(previsores, novo, axis = 0)\n",
    "        #Atualizando a lista normalizados com a lista previsores atualizada\n",
    "        normalizados = normalizar.fit_transform(previsores)\n",
    "        #Recuperando na variável x o último registro que foi inserido na lista normalizados\n",
    "        x = np.array([normalizados[-1]])\n",
    "        #Realizando a nova previsão\n",
    "        prever(x)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
